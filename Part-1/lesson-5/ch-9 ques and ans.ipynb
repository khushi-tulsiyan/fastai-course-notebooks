{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is a continuous variable?\n",
    "\n",
    "Continuous variables are numerical data, such as \"age,\" that can be directly fed to the model, since you can add and multiply them directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is a categorical variable?\n",
    "\n",
    "Categorical variables contain a number of discrete levels, such as \"movie ID,\" for which addition and multiplication don't have meaning (even if they're stored as numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Provide two of the words that are used for the possible values of a categorical variable.\n",
    "\n",
    "For a categorical variable we call the possible values of the variable its \"levels\" (or \"categories\" or \"classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is a dense layer?\n",
    "\n",
    "\"dense layer\" is a term with the same meaning as \"linear layer,\" and the one-hot encoding layers represent inputs.\n",
    "\n",
    "A dense layer is a layer in a neural network that is fully connected to the layer before it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How do entity embeddings reduce memory usage and speed up neural networks?\n",
    "\n",
    "embedding transforms the categorical variables into inputs that are both continuous and meaningful.\n",
    "\n",
    "entity embedding defines a distance measure for categorical variables it can be used for visualizing categorical data and for data clustering.\n",
    "\n",
    "Entity embeddings reduce memory usage and speed up neural networks by representing categorical data (like user IDs, product categories) as low-dimensional vectors instead of using one-hot encoding, which requires a large memory footprint for high cardinality datasets, allowing the network to process information more efficiently and quickly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What kinds of datasets are entity embeddings especially useful for?\n",
    "\n",
    "\n",
    "It is especially useful for datasets with lots of high cardinality features, where other methods tend to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What are the two main families of machine learning algorithms?\n",
    "\n",
    "Ensembles of decision trees (i.e., random forests and gradient boosting machines), mainly for structured data (such as you might find in a database table at most companies)\n",
    "Multilayered neural networks learned with SGD (i.e., shallow and/or deep learning), mainly for unstructured data (such as audio, images, and natural language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Why do some categorical columns need a special ordering in their classes? How do you do this in Pandas?\n",
    "\n",
    "the levels of a categorical variable do not have an intrinsic meaning, unless we manually specify an ordering using Pandas. because the order of the categories can have meaning in the analysis, especially when interpreting trends or visualizing data.\n",
    "\n",
    "In Pandas, you can set the order of categories within a categorical column using the .cat.set_categories() method, specifying the desired order of the categories as a list. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Summarize what a decision tree algorithm does.\n",
    "\n",
    "A decision tree algorithm is a supervised machine learning method that uses a tree-like structure to classify data by making sequential decisions based on features, essentially creating a flowchart where each node represents a question about the data and branches lead to different possible outcomes, ultimately reaching a final prediction at the \"leaf\" node; it works by recursively splitting the data into smaller subsets based on the most important attribute at each step, aiming to create homogeneous groups within each branch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Why is a date different from a regular categorical or continuous variable, and how can you preprocess it to allow it to be used in a model?\n",
    "\n",
    "In order to help our algorithm handle dates intelligently, we'd like our model to know more than whether a date is more recent or less recent than another. We might want our model to make decisions based on that date's day of the week, on whether a day is a holiday, on what month it is in, and so forth. To do this, we replace every date column with a set of date metadata columns, such as holiday, day of week, and month. These columns provide categorical data that we suspect will be useful.\n",
    "\n",
    "we do it using Tabularproc and TabularPandas fastai objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Should you pick a random validation set in the bulldozer competition? If no, what kind of validation set should you pick?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. What is pickle and what is it useful for?\n",
    "\n",
    "\"pickle\" refers to a Python module that allows you to serialize and deserialize Python objects, essentially meaning you can save the state of a trained machine learning model to a file and load it later when needed, enabling you to reuse the model without retraining it from scratch every time you want to make predictions on new data; it's a convenient way to store and retrieve complex data structures like trained models and large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. How are mse, samples, and values calculated in the decision tree drawn in this chapter?\n",
    "\n",
    "The top node represents the initial model before any splits have been done, when all the data is in one group. This is the simplest possible model. It is the result of asking zero questions and will always predict the value to be the average value of the whole dataset. In this case, we can see it predicts a value of 10.10 for the logarithm of the sales price. It gives a mean squared error of 0.48. The square root of this is 0.69. (Remember that unless you see m_rmse, or a root mean squared error, then the value you are looking at is before taking the square root, so it is just the average of the square of the differences.) We can also see that there are 404,710 auction records in this groupâ€”that is the total size of our training set. The final piece of information shown here is the decision criterion for the best split that was found, which is to split based on the coupler_system column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
